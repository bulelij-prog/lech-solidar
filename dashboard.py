"""
NExUS v2.5 - Dashboard Principal
Utilise Vertex AI avec Service Account pour l'authentification Gemini
"""

import streamlit as st
import json
import pandas as pd
from datetime import datetime
from google.oauth2 import service_account
import vertexai
from vertexai.generative_models import GenerativeModel

# ============================================================
# CONFIGURATION STREAMLIT
# ============================================================

st.set_page_config(
    page_title="NExUS v2.5 - Dashboard",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================
# INITIALISATION VERTEX AI AVEC SERVICE ACCOUNT
# ============================================================

@st.cache_resource
def initialize_vertex_ai():
    """
    Initialise Vertex AI avec les credentials du Service Account
    stock√©es dans les secrets Streamlit.
    
    Returns:
        tuple: (project_id, credentials)
    """
    try:
        # R√©cup√®re le JSON du service account depuis les secrets
        service_account_json = st.secrets.get("GCP_SERVICE_ACCOUNT_JSON")
        
        if not service_account_json:
            st.error("‚ùå Erreur: Le secret GCP_SERVICE_ACCOUNT_JSON n'est pas configur√©")
            st.error("Ajoute-le dans Streamlit Secrets avec le contenu de ta cl√© JSON")
            st.stop()
        
        # Parse le JSON
        try:
            credentials_dict = json.loads(service_account_json)
        except json.JSONDecodeError:
            st.error("‚ùå Erreur: GCP_SERVICE_ACCOUNT_JSON n'est pas un JSON valide")
            st.stop()
        
        # Cr√©e les credentials
        credentials = service_account.Credentials.from_service_account_info(
            credentials_dict
        )
        
        # R√©cup√®re le project ID
        project_id = credentials_dict.get("project_id")
        
        if not project_id:
            st.error("‚ùå Erreur: Impossible de r√©cup√©rer le project_id")
            st.stop()
        
        # Initialise Vertex AI
        vertexai.init(project=project_id, credentials=credentials)
        
        return project_id, credentials
    
    except Exception as e:
        st.error(f"‚ùå Erreur d'initialisation Vertex AI: {str(e)}")
        st.stop()


# ============================================================
# FONCTIONS POUR APPELER GEMINI
# ============================================================

def call_gemini_api(prompt: str, model_name: str = "gemini-2.0-flash") -> str:
    """
    Appelle l'API Gemini via Vertex AI.
    
    Args:
        prompt (str): Le prompt √† envoyer √† Gemini
        model_name (str): Le mod√®le Gemini √† utiliser
    
    Returns:
        str: La r√©ponse du mod√®le ou None si erreur
    """
    try:
        model = GenerativeModel(model_name=model_name)
        
        response = model.generate_content(
            prompt,
            generation_config={
                "max_output_tokens": 2048,
                "temperature": 0.7,
            }
        )
        
        return response.text
    
    except Exception as e:
        return f"Erreur Gemini: {str(e)}"


# ============================================================
# INITIALISATION AU D√âMARRAGE
# ============================================================

# Initialise Vertex AI
project_id, credentials = initialize_vertex_ai()

# Message de confirmation
st.success(f"‚úì Vertex AI initialis√© avec le projet: {project_id}")


# ============================================================
# INTERFACE STREAMLIT
# ============================================================

st.title("üöÄ NExUS v2.5 - Dashboard")
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    model_choice = st.selectbox(
        "Choisir le mod√®le Gemini:",
        ["gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"]
    )
    
    temperature = st.slider(
        "Temp√©rature (cr√©ativit√©):",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1
    )
    
    st.divider()
    st.info(f"üìä Projet GCP: `{project_id}`")


# Section principale
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("üí¨ Testeur Gemini")
    
    prompt = st.text_area(
        "Entrez votre prompt:",
        placeholder="Posez une question ou donnez une t√¢che √† Gemini...",
        height=150
    )
    
    if st.button("üîÑ Envoyer √† Gemini", use_container_width=True):
        if prompt.strip():
            with st.spinner("‚è≥ Gemini r√©fl√©chit..."):
                response = call_gemini_api(prompt, model_name=model_choice)
                
                if response and not response.startswith("Erreur"):
                    st.success("‚úì R√©ponse re√ßue")
                    st.markdown("---")
                    st.write(response)
                else:
                    st.error(response)
        else:
            st.warning("‚ö†Ô∏è Veuillez entrer un prompt")

with col2:
    st.subheader("üìà Stats")
    
    st.metric(
        "Mod√®le Actif",
        model_choice.split("-")[1]
    )
    
    st.metric(
        "Temp√©rature",
        temperature
    )
    
    st.metric(
        "Timestamp",
        datetime.now().strftime("%H:%M:%S")
    )


# Section historique (optionnel)
st.divider()
st.subheader("üìù Historique")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if st.session_state.chat_history:
    for i, entry in enumerate(st.session_state.chat_history):
        with st.expander(f"Interaction {i+1}: {entry['prompt'][:50]}..."):
            st.write(f"**Prompt:** {entry['prompt']}")
            st.write(f"**R√©ponse:** {entry['response']}")
            st.caption(f"üïê {entry['timestamp']}")
else:
    st.info("Aucune interaction pour le moment")


# Footer
st.divider()
st.caption("NExUS v2.5 | Powered by Vertex AI + Streamlit")
