"""
NExUS v3.0 - Assistant IA Vertex AI
D√©l√©gation CGSP ALR
Authentification par Base64 s√©curis√©e
"""

import streamlit as st
import base64
import json
import sys
from google.oauth2 import service_account
import vertexai
from vertexai.generative_models import GenerativeModel

# Configuration Streamlit
st.set_page_config(
        page_title="NExUS v3.0 - CGSP",
        page_icon="üîê",
        layout="wide",
        initial_sidebar_state="expanded"
)

# ============================================================================
# AUTHENTIFICATION & DIAGNOSTIQUE
# ============================================================================

def load_credentials_from_base64():
        """Charge et valide les credentials depuis Base64"""
        try:
                    if "GCP_CREDENTIALS_BASE64" not in st.secrets:
                                    return None, "‚ùå Secret GCP_CREDENTIALS_BASE64 introuvable"

                    b64_string = st.secrets["GCP_CREDENTIALS_BASE64"]
                    json_bytes = base64.b64decode(b64_string)
                    creds_dict = json.loads(json_bytes)

        credentials = service_account.Credentials.from_service_account_info(
                creds_dict,
                scopes=["https://www.googleapis.com/auth/cloud-platform"]
        )
            return credentials, "‚úÖ Credentials charg√©s"

except Exception as e:
        return None, f"‚ùå Erreur d√©codage Base64: {str(e)}"

def init_vertex_ai(credentials):
        """Initialise Vertex AI"""
    try:
                vertexai.init(
                                project="syndicat-novembre-2025",
                                location="europe-west1",
                                credentials=credentials
                )
                return True, "‚úÖ Vertex AI initialis√©"
except Exception as e:
        return False, f"‚ùå Erreur Vertex AI: {str(e)}"

def test_gemini_model():
        """Teste le mod√®le Gemini 1.5 Flash"""
    try:
                model = GenerativeModel("gemini-1.5-flash-001")
                return True, "‚úÖ Mod√®le Gemini 1.5 Flash disponible"
except Exception as e:
        return False, f"‚ùå Erreur mod√®le: {str(e)}"

def run_diagnostics():
        """Lance le diagnostic complet au d√©marrage"""
    diag_results = []

    # Test 1 : Credentials
    creds, msg_creds = load_credentials_from_base64()
    diag_results.append(("Secret Base64", msg_creds, creds is not None))

    if creds is None:
                return diag_results, None

    # Test 2 : Vertex AI
    success_va, msg_va = init_vertex_ai(creds)
    diag_results.append(("Vertex AI Init", msg_va, success_va))

    if not success_va:
                return diag_results, creds

    # Test 3 : Mod√®le Gemini
    success_model, msg_model = test_gemini_model()
    diag_results.append(("Mod√®le Gemini 1.5", msg_model, success_model))

    return diag_results, creds if success_model else None

# ============================================================================
# INTERFACE DIAGNOSTIQUE (SIDEBAR)
# ============================================================================

with st.sidebar:
        st.header("üîê NExUS v3.0")
    st.caption("Assistant IA - D√©l√©gation CGSP ALR")
    st.divider()

    # Lance les diagnostics
    diag_results, credentials = run_diagnostics()

    st.subheader("üìä √âtat du syst√®me")

    for test_name, message, success in diag_results:
                col1, col2 = st.columns([0.3, 0.7])
                with col1:
                                st.write("‚úÖ" if success else "‚ùå")
                            with col2:
                    st.caption(test_name)
                                        st.caption(message)
        st.divider()

    # Affiche le statut global
    all_ok = all(result[2] for result in diag_results)
    if all_ok:
                st.success("üü¢ TOUS SYST√àMES OP√âRATIONNELS")
        system_ready = True
else:
        st.error("üî¥ SYST√àME EN ERREUR - V√©rifier la configuration")
        system_ready = False

# ============================================================================
# FONCTION PRINCIPALE DE REQU√äTE
# ============================================================================

def query_nexus(prompt: str) -> str:
        """Envoie une requ√™te au mod√®le Gemini"""

    if not system_ready or credentials is None:
                return "‚ùå Syst√®me non initialis√©. V√©rifiez la configuration dans le diagnostic."

    try:
                # R√©initialise Vertex AI (√©vite les probl√®mes de session)
                vertexai.init(
                                project="syndicat-novembre-2025",
                                location="europe-west1",
                                credentials=credentials
                )

        # Cr√©e le mod√®le
        model = GenerativeModel(
                        model_name="gemini-1.5-flash-001",
                        system_instruction="""Tu es NExUS, l'assistant IA officiel de la d√©l√©gation CGSP ALR.
                        - R√©ponds toujours en fran√ßais
                        - Sois pr√©cis et professionnel
                        - Fournis des r√©ponses structur√©es et faciles √† comprendre
                        - Si tu ne sais pas, dis-le clairement"""
        )

        # G√©n√®re la r√©ponse
        response = model.generate_content(
                        prompt,
                        generation_config={
                                            "max_output_tokens": 2048,
                                            "temperature": 0.7,
                                            "top_p": 0.9,
                                            "top_k": 40
                        }
        )

        return response.text

except Exception as e:
        return f"‚ö†Ô∏è Erreur lors du traitement: {type(e).__name__}: {str(e)}"

# ============================================================================
# INTERFACE PRINCIPALE
# ============================================================================

st.title("ü§ñ NExUS v3.0")
st.markdown("**Assistant IA Secteur Aide aux Personnes**")
st.markdown("D√©l√©gation CGSP ALR")
st.divider()

# Initialise l'historique de messages
if "messages" not in st.session_state:
        st.session_state.messages = []

# Affiche l'historique
for message in st.session_state.messages:
        with st.chat_message(message["role"]):
                    st.markdown(message["content"])

# Entr√©e utilisateur
if system_ready:
        prompt = st.chat_input("Posez votre question √† NExUS...")

    if prompt:
                # Affiche le message utilisateur
                with st.chat_message("user"):
                                st.markdown(prompt)
                            st.session_state.messages.append({"role": "user", "content": prompt})

        # Traite la requ√™te
        with st.chat_message("assistant"):
                        with st.spinner("‚öôÔ∏è Traitement en cours..."):
                                            response = query_nexus(prompt)
                                            st.markdown(response)

                    st.session_state.messages.append({"role": "assistant", "content": response})

else:
    st.warning("‚ö†Ô∏è Le syst√®me n'est pas op√©rationnel. V√©rifiez la configuration dans le volet de diagnostic.")

st.divider()
st.caption("NExUS v3.0 - Powered by Google Gemini 1.5 Flash on Vertex AI")
